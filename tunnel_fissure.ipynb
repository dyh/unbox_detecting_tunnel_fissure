{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tunnel_fissure.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEL8iUf4fvaI"
      },
      "source": [
        "# Unbox AI\n",
        "\n",
        "> AI开箱\n",
        "\n",
        "- unbox opensource projects and products of Artificial Intelligence\n",
        "\n",
        "> 人工智能开源项目和产品开箱"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RltHRxvZg0uO"
      },
      "source": [
        "\n",
        "## welcome to subscribe my channel\n",
        "\n",
        "> 欢迎订阅我的频道\n",
        "\n",
        "- [youtube channel 油管频道](https://youtube.com/channel/UCAebg3DDFtidQJ0Jp20kyaw)\n",
        "- [bilibili channel b站频道](https://space.bilibili.com/326361150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB_yQTqCgOKQ"
      },
      "source": [
        "# Unbox 'detecting tunnel fissure'\n",
        "\n",
        "> 开箱 '隧道裂缝检测'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fskYLM2g7BZ"
      },
      "source": [
        "\n",
        "## video\n",
        "\n",
        "> 视频\n",
        "\n",
        "- youtube video\n",
        "\n",
        "- b站视频\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zlTCW9bDH-k"
      },
      "source": [
        "## 1.mount google drive folder\n",
        "\n",
        "> 挂载 google drive 云端硬盘的文件夹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0kTheKp7gv-"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4dzHwD2jmCq"
      },
      "source": [
        "## 2.clone project files to google drive folder\n",
        "\n",
        "> 克隆项目文件到 google drive 云端硬盘的目录"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80qdBsYVkF83"
      },
      "source": [
        "!git clone 'https://github.com/dyh/unbox_detecting_tunnel_fissure.git' '/content/drive/My Drive/tunnel_fissure'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeSRuj15jVdT"
      },
      "source": [
        "## 3.install dependencies\n",
        "\n",
        "> 安装依赖项"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpPo-NwK4qsS"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1 'pycocotools>=2.0.1'\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab\n",
        "\n",
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.6)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "assert torch.__version__.startswith(\"1.6\")\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgK6W3ohnbnt"
      },
      "source": [
        "---\n",
        "\n",
        "***please make sure of that you have click the [ RESTART RUNTIME ] button -> [ YES ] button to restart colab runtime***\n",
        "\n",
        "***请确认您点击了 [ RESTART RUNTIME ] 按钮 -> [ 确定 ] 按钮，来重新加载 colab 运行时***\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GkWuOJmMr6J"
      },
      "source": [
        "## 4.annotate your own training sample (optional)\n",
        "\n",
        "> 标注您自己的训练样本（可选）\n",
        "\n",
        "### here's how to annotate sample from 0 to 1, if you don't care about annotation, you can ignore this section.\n",
        "\n",
        "> 这里介绍如何从0到1进行样本标注，如果您对样本标注不感兴趣，可以忽略这一章节。\n",
        "\n",
        "1. i have install the 'google drive backup and sync' app, which automatically synchronizes the google drive files on my machine for easy annotation. you can download it at https://www.google.com/drive/download/\n",
        "\n",
        "> 我在本地电脑安装了 'google drive备份和同步' 应用，便于同步标注文件到 google drive云端硬盘，您可以在 https://www.google.com/drive/download/ 下载这个app\n",
        "\n",
        "2. in the google drive folder, go to '/content/drive/My Drive/tunnel_fissure/images/train' folder, and backup the origin 'via_region_data.json' file, change its name to 'via_region_data_bak.json'\n",
        "\n",
        "> 在 google drive云端硬盘 访问 '/content/drive/My Drive/tunnel_fissure/images/train'文件夹，将原始文件 'via_region_data.json' 改名为 'via_region_data_bak.json' 用于备份。\n",
        "\n",
        "3. go to VGG Image Annotator (VIA for short) website http://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html\n",
        "\n",
        "> 访问 VGG图片标注工具（简称 VIA）的网站 http://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html\n",
        "\n",
        "4. remove 2 demo images in 'VIA', swan and 'The Death of Socrates'\n",
        "\n",
        "> 从 VIA 中移除2个默认的图片，天鹅和《苏格拉底之死》\n",
        "\n",
        "5. add your images to 'VIA', now we add images from train folder\n",
        "\n",
        "> 将 train 目录下的图片添加到 'VIA'\n",
        "\n",
        "6. config attributes of Region Attributes\n",
        "\n",
        "> 设置标注区域的属性\n",
        "\n",
        "  * remove 'image_quality' attribute\n",
        "\n",
        "  > 移除 'image_quality' 图像质量 属性\n",
        "\n",
        "  * change default value of 'name' attribute, from 'not_defined' to 'fissure'\n",
        "\n",
        "  > 改变 'name' 属性的默认值，从 'not_defined' 改为 'fissure'\n",
        "\n",
        "  * add 'fissure' and 'water' to 'type' attribute, remove other values\n",
        "\n",
        "  > 将 'fissure' 和 'water' 添加到 'type' 属性中，并移除其他值\n",
        "\n",
        "  * annotate some fissure regions and water regions\n",
        "\n",
        "  > 标注一些裂缝区域和渗水区域\n",
        "\n",
        "  * click [ Project -> Save ] to save project file 'project.json'\n",
        "\n",
        "  > 点击 [ Project -> Save ] 保存项目文件，以便下次继续标注时使用\n",
        "\n",
        "  * click [ Annotation -> Export Annotations (as json) ] to export json file 'data_json.josn', change its name to 'via_region_data.json'\n",
        "\n",
        "  > 点击 [ Annotation -> Export Annotations (as json) ] 导出标注数据，并且重命名为 'via_region_data.json' 文件\n",
        "\n",
        "  * we could use 'google drive backup and sync' app to sync 'via_region_data.json' file from download folder to '/content/drive/My Drive/tunnel_fissure/images/train' folder\n",
        "\n",
        "  > 我们可以使用 'google drive 备份和同步' app，将 'via_region_data.json' 文件从本地同步到 google drive云端硬盘的 '/content/drive/My Drive/tunnel_fissure/images/train' 目录\n",
        "\n",
        "\n",
        "7. now you have your own training dataset 'via_region_data.json'\n",
        "\n",
        "> 现在您拥有了自己的训练数据集 'via_region_data.json'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CyMZCQ7lpe4"
      },
      "source": [
        "## 5.import modules\n",
        "\n",
        "> 导入模块"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f0YbcBk6S5H"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvWKLj4llwEQ"
      },
      "source": [
        "## 6.register train & val dataset\n",
        "\n",
        "> 注册训练数据集和验证数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlmv_dlNm8lF"
      },
      "source": [
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_fissures_dicts(img_dir):\n",
        "    json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for idx, v in enumerate(imgs_anns.values()):\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(img_dir, v[\"filename\"])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        list_annos = v[\"regions\"]\n",
        "\n",
        "        objs = []\n",
        "        # for _, anno in annos.items():\n",
        "        for dict_anno in list_annos:\n",
        "            # assert not anno[\"region_attributes\"]\n",
        "            anno = dict_anno[\"shape_attributes\"]\n",
        "            px = anno[\"all_points_x\"]\n",
        "            py = anno[\"all_points_y\"]\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            # get type from region_attributes to set different category_id\n",
        "            attr1 = dict_anno[\"region_attributes\"]\n",
        "            type1 = attr1[\"type\"]\n",
        "\n",
        "            if type1 == \"fissure\":\n",
        "                cat_id = 0\n",
        "            elif type1 == \"water\":\n",
        "                cat_id = 1\n",
        "            else:\n",
        "                cat_id = 0\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": cat_id,\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "for d in [\"train\", \"val\"]:\n",
        "    DatasetCatalog.register(\"fissures_\" + d, lambda d=d: get_fissures_dicts(os.path.join(\"/content/drive/My Drive/tunnel_fissure/images\", d)))\n",
        "    MetadataCatalog.get(\"fissures_\" + d).set(thing_classes=[\"fissure\",\"water\"])\n",
        "    \n",
        "fissures_metadata = MetadataCatalog.get(\"fissures_train\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8QcQjiOPMx4"
      },
      "source": [
        "## 7.preview train dataset\n",
        "\n",
        "> 预览训练数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFMQZ0BcXI-Z"
      },
      "source": [
        "dataset_dicts = get_fissures_dicts(\"/content/drive/My Drive/tunnel_fissure/images/train\")\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=fissures_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXBWpqE6ppsx"
      },
      "source": [
        "## 8.train a model\n",
        "> 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63hQDIN5XPBM"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"fissures_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025   # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 300   # you will need to train longer for a practical dataset\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # default: 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2   # has two classes(fissure, water).\n",
        "\n",
        "cfg.OUTPUT_DIR = '/content/drive/My Drive/tunnel_fissure/output'\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "# trainer.resume_or_load(resume=True)\n",
        "trainer.train()\n",
        "\n",
        "print('train done.')\n",
        "\n",
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/drive/My Drive/tunnel_fissure/output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3lp7QQzvIc5"
      },
      "source": [
        "## 9.predict images\n",
        "\n",
        "> 检测图片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qFrv2fNrfEj"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "cfg.OUTPUT_DIR = '/content/drive/My Drive/tunnel_fissure/output'\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "test_image_folder = '/content/drive/My Drive/tunnel_fissure/images/test'\n",
        "files = os.listdir(test_image_folder)\n",
        "# sort by file name\n",
        "files.sort()\n",
        "\n",
        "for file_name in files:\n",
        "    # filter jpg files\n",
        "    if file_name[-4:] == '.jpg':\n",
        "        image_path = os.path.join(test_image_folder, file_name)\n",
        "\n",
        "        # load the origin image\n",
        "        im = cv2.imread(image_path)\n",
        "        \n",
        "        outputs = predictor(im)   # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "        v = Visualizer(im[:, :, ::-1],\n",
        "                      metadata=fissures_metadata, \n",
        "                      scale=0.5,   # zoom out image\n",
        "                      instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "        )\n",
        "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "        image_obj = out.get_image()[:, :, ::-1]\n",
        "        cv2.imwrite(os.path.join(cfg.OUTPUT_DIR, file_name), image_obj)\n",
        "        cv2_imshow(image_obj)\n",
        "\n",
        "print('predict done.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcRvx2Y15dhL"
      },
      "source": [
        "## thanks for watching\n",
        "\n",
        "welcome to leave message, tell me which AI opensource project you want to see.\n",
        "\n",
        "> 如果您想看到哪个开源AI项目被开箱，欢迎留言。"
      ]
    }
  ]
}